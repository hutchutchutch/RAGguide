I‚Äôm building a web app where users can upload PDF books, configure how the content is chunked and embedded into a vector store, and chat with a language model about the content. They can manually label chunks, build a knowledge graph from them, and compare the results of standard RAG versus GraphRAG retrieval strategies.

Users should also be able to:

See a breakdown of the steps involved in the RAG pipeline

Inspect the final prompt sent to the LLM, including the retrieved chunks and system prompt

Manually label retrieved chunks and build graph nodes and relationships

üñ• Pages and Components
1. Dashboard Page
This is the main interaction surface after uploading a book.

Left Sidebar: ‚ÄúRAG Pipeline Inspector‚Äù
Book Selector (dropdown)

Embedding Settings Form

Chunk Size (input)

Overlap (input)

Text Cleaner (dropdown)

Chunking Strategy: Recursive / Semantic (toggle)

CTA: ‚ÄúRechunk + Embed‚Äù

RAG Pipeline Steps Viewer

Step 1: Preprocessed text output

Step 2: Final chunks preview

Step 3: Vector search results (top-k)

Step 4: Graph-enhanced context preview

Step 5: Final prompt preview (system + user + context)

CTA: ‚ÄúRun RAG‚Äù or ‚ÄúAsk Question‚Äù

Main Panel: ‚ÄúChat Interface‚Äù
Input field for user query

Chat history (conversation format)

Toggle to view:

Vanilla RAG retrieved chunks

GraphRAG chunks

Final prompt sent to LLM

CTA: ‚ÄúSend‚Äù

Right Sidebar: ‚ÄúKnowledge Graph Builder‚Äù
Visual Graph View (nodes and relationships)

Manual Chunk Labeler (shows chunk text + tagging tools)

Node Creation Panel (type, label, description)

Edge Creator (source, target, type)

CTAs:

‚ÄúCreate Node from Chunk‚Äù

‚ÄúLink Selected Nodes‚Äù

‚ÄúSuggest Related Chunks‚Äù

‚úÖ Key CTAs
Upload PDF

Configure Embedding Settings

Rechunk + Embed

Run RAG / Ask Question

View Prompt Sent to LLM

Label Chunk

Create Graph Node

Link Graph Nodes

üóÉÔ∏è Postgres Data Model (Updated)
sql
Copy
Edit
books (
  id UUID PRIMARY KEY,
  title TEXT,
  filename TEXT,
  uploaded_at TIMESTAMP
)

embedding_settings (
  id UUID PRIMARY KEY,
  chunk_size INTEGER,
  overlap INTEGER,
  cleaner TEXT,
  strategy TEXT, -- 'recursive' | 'semantic'
  model TEXT,
  created_at TIMESTAMP
)

chunks (
  id UUID PRIMARY KEY,
  book_id UUID REFERENCES books(id),
  chunk_index INTEGER,
  text TEXT,
  embedding VECTOR,
  page_number INTEGER,
  embedding_settings_id UUID REFERENCES embedding_settings(id)
)

chat_sessions (
  id UUID PRIMARY KEY,
  book_id UUID REFERENCES books(id),
  question TEXT,
  llm_response TEXT,
  created_at TIMESTAMP
)

chat_chunks (
  id UUID PRIMARY KEY,
  chat_id UUID REFERENCES chat_sessions(id),
  chunk_id UUID REFERENCES chunks(id),
  rank INTEGER,
  retrieval_type TEXT -- 'rag' | 'graphrag'
)

llm_prompts (
  id UUID PRIMARY KEY,
  chat_id UUID REFERENCES chat_sessions(id),
  system_prompt TEXT,
  context_chunks TEXT[], -- array of chunk IDs or raw text
  final_prompt TEXT
)

nodes (
  id UUID PRIMARY KEY,
  book_id UUID REFERENCES books(id),
  label TEXT,
  type TEXT,
  description TEXT
)

edges (
  id UUID PRIMARY KEY,
  source_node_id UUID REFERENCES nodes(id),
  target_node_id UUID REFERENCES nodes(id),
  label TEXT,
  explanation TEXT
)